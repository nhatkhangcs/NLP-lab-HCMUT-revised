{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Combine Word2Vec along with CNN for Text Classification**"]},{"cell_type":"markdown","metadata":{},"source":["## **Importing Libraries**"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"8TFX7wSAmg9y"},"outputs":[],"source":["try:\n","    import tensorflow as tf\n","except ImportError:\n","    !pip install tensorflow\n","    import tensorflow as tf\n","\n","try:\n","    import pandas as pd\n","except ImportError:\n","    !pip install pandas\n","    import pandas as pd\n","\n","try:\n","    import numpy as np\n","except ImportError:\n","    !pip install numpy\n","    import numpy as np\n","\n","try:\n","    from string import digits\n","except ImportError:\n","    !pip install string\n","    from string import digits\n","\n","try:\n","    from collections import Counter\n","except ImportError:\n","    !pip install collections\n","    from collections import Counter\n","\n","try:\n","    from pyvi import ViTokenizer\n","except ImportError:\n","    !pip install pyvi\n","    from pyvi import ViTokenizer\n","\n","try:\n","    from gensim.models.word2vec import Word2Vec\n","except ImportError:\n","    !pip install gensim\n","    from gensim.models.word2vec import Word2Vec\n","\n","try:\n","    from keras.utils import to_categorical\n","except ImportError:\n","    !pip install keras\n","    from keras.utils import to_categorical\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from utils.helper_function import *"]},{"cell_type":"markdown","metadata":{},"source":["## **Downloading the Dataset**"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1q3myiaORcL3fbeks8ExZZcqefFtHthPD\n","To: e:\\General_Subjects\\Natural Language Processing\\Lab-NLP\\datasets\\vlsp_sentiment_train.csv\n","100%|██████████| 858k/858k [00:00<00:00, 1.78MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1jofip_UbAXzzJwrqacVTJ7183mmpBQXe\n","To: e:\\General_Subjects\\Natural Language Processing\\Lab-NLP\\datasets\\vlsp_sentiment_test.csv\n","100%|██████████| 159k/159k [00:00<00:00, 637kB/s]\n"]}],"source":["URLs = {\n","    \"https://drive.google.com/file/d/1q3myiaORcL3fbeks8ExZZcqefFtHthPD/view?usp=drive_link\": \"datasets/vlsp_sentiment_train.csv\",\n","    \"https://drive.google.com/file/d/1jofip_UbAXzzJwrqacVTJ7183mmpBQXe/view?usp=drive_link\": \"datasets/vlsp_sentiment_test.csv\",\n","}\n","\n","for key, value in URLs.items():\n","    download_data(key, value)"]},{"cell_type":"markdown","metadata":{},"source":["Get dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"a7lMy03omg93","scrolled":true},"outputs":[],"source":["data_train = pd.read_csv(\"datasets/vlsp_sentiment_train.csv\", sep='\\t')\n","data_train.columns =['Class', 'Data']\n","data_test = pd.read_csv(\"datasets/vlsp_sentiment_test.csv\", sep='\\t')\n","data_test.columns =['Class', 'Data']"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":944,"status":"ok","timestamp":1653989301990,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"4HR1jAzImg94","outputId":"8e324c8c-0dbb-4a69-aeff-b03e40766c7e"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5100, 2)\n","(1050, 2)\n"]}],"source":["print(data_train.shape)\n","print(data_test.shape)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"jvrbwPfZmg95"},"outputs":[],"source":["labels = data_train.iloc[:, 0].values\n","reviews = data_train.iloc[:, 1].values"]},{"cell_type":"markdown","metadata":{},"source":["### One-hot encoding the labels"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"3HlbVeHimg95"},"outputs":[],"source":["encoded_labels = []\n","\n","for label in labels:\n","    if label == -1:\n","        encoded_labels.append([1,0,0])\n","    elif label == 0:\n","        encoded_labels.append([0,1,0])\n","    else:\n","        encoded_labels.append([0,0,1])\n","\n","encoded_labels = np.array(encoded_labels)  "]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Lm4OCwxXmg96"},"outputs":[],"source":["reviews_processed = []\n","unlabeled_processed = [] \n","for review in reviews:\n","    review_cool_one = ''.join([char for char in review if char not in digits])\n","    reviews_processed.append(review_cool_one)"]},{"cell_type":"markdown","metadata":{},"source":["Use PyVi for Vietnamese word tokenizer"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"nW2OZgkgmg97"},"outputs":[],"source":["word_reviews = []\n","all_words = []\n","for review in reviews_processed:\n","    review = ViTokenizer.tokenize(review.lower())\n","    word_reviews.append(review.split())\n","   "]},{"cell_type":"markdown","metadata":{},"source":["Define the parameters:\n","- `EMBEDDING_DIM` is the dimension of the word embeddings. It's usually set to 100, 200, 300 or higher. The higher the dimension, the more context the word embeddings can capture, but the more computationally expensive it is to train the model.\n","- `MAX_SEQUENCE_LENGTH` is the maximum length of the text sequences. Text sequences that are shorter than this are padded with zeros, and sequences that are longer are truncated to this length. This is done to ensure that the input to the model has a consistent shape.\n","- `VOCAB_SIZE` is the size of the vocabulary. This is the number of unique words in the dataset's vocabulary. It is used to specify the input size of the embedding layer."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"pTb0MeDRmg98"},"outputs":[],"source":["EMBEDDING_DIM = 400 # how big is each word vector\n","MAX_VOCAB_SIZE = 10000 # how many unique words to use (i.e num rows in embedding vector)\n","MAX_SEQUENCE_LENGTH = 300 # max number of words in a comment to use"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"jW-7mKtWmg9-"},"outputs":[],"source":["try:\n","    from tensorflow.keras.preprocessing.text import Tokenizer\n","except ImportError:\n","    !pip install tensorflow\n","    from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","try:\n","    from tensorflow.keras.preprocessing.sequence import pad_sequences\n","except ImportError:\n","    !pip install tensorflow\n","    from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","try:\n","    from tensorflow.keras.utils import to_categorical\n","except ImportError:\n","    !pip install tensorflow\n","    from tensorflow.keras.utils import to_categorical"]},{"cell_type":"markdown","metadata":{},"source":["Tokenize the text data"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"-BHpPSLTmg9_"},"outputs":[],"source":["tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, lower=True, char_level=False)\n","tokenizer.fit_on_texts(word_reviews)\n","sequences_train = tokenizer.texts_to_sequences(word_reviews)\n","word_index = tokenizer.word_index"]},{"cell_type":"markdown","metadata":{},"source":["Pad the sequences"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"LlV3M2dimg9_"},"outputs":[],"source":["data = pad_sequences(sequences_train, maxlen=MAX_SEQUENCE_LENGTH)\n","labels = encoded_labels"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1653989306259,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"4dl9VZ3Rmg-A","outputId":"0d43e170-e903-4d5b-f3ec-18a8b911d072"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X train and X validation tensor: (5100, 300)\n","Shape of label train and validation tensor: (5100, 3)\n"]}],"source":["print('Shape of X train and X validation tensor:', data.shape)\n","print('Shape of label train and validation tensor:', labels.shape)"]},{"cell_type":"markdown","metadata":{},"source":["Now, we will creaate Word2Vec model"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["import gensim\n","from gensim.models import Word2Vec\n","from gensim.utils import simple_preprocess\n","\n","from gensim.models.keyedvectors import KeyedVectors\n","\n","CHECKPOINT = 'checkpoints/vi-model-CBOW.bin'\n","if not os.path.exists(CHECKPOINT):\n","    # https://drive.google.com/file/d/1ibVpNvQci2T-phUeV8aT8kfFd8eRkyqL/view?usp=sharing\n","    download_data(url='https://drive.google.com/file/d/1ibVpNvQci2T-phUeV8aT8kfFd8eRkyqL/view?usp=sharing', output_path=CHECKPOINT, fuzzy=True)\n","\n","word_vectors = KeyedVectors.load_word2vec_format(CHECKPOINT, binary=True)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"-KKSjJdJmg-A"},"outputs":[],"source":["vocabulary_size=min(len(word_index)+1,MAX_VOCAB_SIZE)\n","embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    if i>=MAX_VOCAB_SIZE:\n","        continue\n","    try:\n","        embedding_vector = word_vectors[word]\n","        embedding_matrix[i] = embedding_vector\n","    except KeyError:\n","        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n","\n","del(word_vectors)"]},{"cell_type":"markdown","metadata":{},"source":["Create embedding layer.\n","\n","Actually, we can use the pre-trained Word2Vec model to create the embedding layer. However, in this notebook, we will train the Word2Vec model from scratch."]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["from keras.layers import Embedding\n","embedding_layer = Embedding(vocabulary_size,\n","                            EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            trainable=True)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":381,"status":"ok","timestamp":1653989417080,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"njBANdn5mg-B","outputId":"24647910-9144-4987-83a2-fe64e64a04ac"},"outputs":[],"source":["from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Embedding, Dropout,concatenate\n","from tensorflow.keras.layers import Reshape, Flatten\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import regularizers"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["sequence_length = data.shape[1]\n","filter_sizes = [3,4,5]\n","num_filters = 100\n","drop = 0.5"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["inputs = Input(shape=(sequence_length,))\n","embedding = embedding_layer(inputs)\n","# reshape = Reshape((sequence_length,EMBEDDING_DIM,1))(embedding)"]},{"cell_type":"markdown","metadata":{},"source":["Create Conv1D layes with:\n","- activation function: ReLU\n","- kernel regularizer: L2"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["conv_0 = Conv1D(num_filters, filter_sizes[0],activation='relu',kernel_regularizer=regularizers.l2(0.01))(embedding)\n","conv_1 = Conv1D(num_filters, filter_sizes[1],activation='relu',kernel_regularizer=regularizers.l2(0.01))(embedding)\n","conv_2 = Conv1D(num_filters, filter_sizes[2],activation='relu',kernel_regularizer=regularizers.l2(0.01))(embedding)"]},{"cell_type":"markdown","metadata":{},"source":["Create max pooling layer"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["maxpool_0 = MaxPooling1D(sequence_length - filter_sizes[0] + 1, strides=1)(conv_0)\n","maxpool_1 = MaxPooling1D(sequence_length - filter_sizes[1] + 1, strides=1)(conv_1)\n","maxpool_2 = MaxPooling1D(sequence_length - filter_sizes[2] + 1, strides=1)(conv_2)"]},{"cell_type":"markdown","metadata":{},"source":["Step by step, we will create the stacked layers to build the model"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["merged_tensor = concatenate([maxpool_0, maxpool_1, maxpool_2], axis=1)\n","flatten = Flatten()(merged_tensor)\n","reshape = Reshape((3*num_filters,))(flatten)\n","dropout = Dropout(drop)(flatten)\n","output = Dense(units=3, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["# this creates a model that includes\n","model = Model(inputs, output)\n","\n","adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_2\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,167,600</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">298</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">120,100</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">297</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">160,100</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">296</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">200,100</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ max_pooling1d_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ max_pooling1d_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ max_pooling1d_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ max_pooling1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","│                     │                   │            │ max_pooling1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m400\u001b[0m)  │  \u001b[38;5;34m3,167,600\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n","│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m298\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │    \u001b[38;5;34m120,100\u001b[0m │ embedding_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m297\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │    \u001b[38;5;34m160,100\u001b[0m │ embedding_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m296\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │    \u001b[38;5;34m200,100\u001b[0m │ embedding_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ max_pooling1d_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n","│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ max_pooling1d_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ max_pooling1d_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_6[\u001b[38;5;34m…\u001b[0m │\n","│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ max_pooling1d_7[\u001b[38;5;34m…\u001b[0m │\n","│                     │                   │            │ max_pooling1d_8[\u001b[38;5;34m…\u001b[0m │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m903\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,648,803</span> (13.92 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,648,803\u001b[0m (13.92 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,648,803</span> (13.92 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,648,803\u001b[0m (13.92 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["Define early stopping"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["#define callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n","callbacks_list = [early_stopping]"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10375,"status":"ok","timestamp":1653989547863,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"Jn0dBlzjmg-D","outputId":"be7de957-bf78-4fff-bc31-b5e586f705fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 962ms/step - accuracy: 0.4027 - loss: 7.8806 - val_accuracy: 0.1745 - val_loss: 6.3770\n","Epoch 2/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step - accuracy: 0.6195 - loss: 5.6594 - val_accuracy: 0.0853 - val_loss: 6.7725\n","Epoch 3/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.7140 - loss: 4.6781 - val_accuracy: 0.0510 - val_loss: 6.3010\n","Epoch 4/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.7847 - loss: 4.0193 - val_accuracy: 0.1127 - val_loss: 5.3863\n","Epoch 5/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.8451 - loss: 3.4938 - val_accuracy: 0.0686 - val_loss: 5.1837\n","Epoch 6/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.8796 - loss: 3.0589 - val_accuracy: 0.0873 - val_loss: 4.8096\n","Epoch 7/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.9046 - loss: 2.6777 - val_accuracy: 0.0725 - val_loss: 4.5703\n","Epoch 8/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.9203 - loss: 2.3599 - val_accuracy: 0.0686 - val_loss: 4.2573\n","Epoch 9/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.9300 - loss: 2.0930 - val_accuracy: 0.0794 - val_loss: 4.0271\n","Epoch 10/10\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.9439 - loss: 1.8459 - val_accuracy: 0.0686 - val_loss: 3.8576\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x27946f51a90>"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(data, labels, validation_split=0.2,\n","          epochs=10, batch_size=256, callbacks=callbacks_list, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["Now let's test the model"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"8XoN2UOamg-D"},"outputs":[],"source":["labels_test = data_test.iloc[:, 0].values\n","reviews_test = data_test.iloc[:, 1].values"]},{"cell_type":"markdown","metadata":{},"source":["Also need to one-hot encode the labels for the test set"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"PwiYb3Ohmg-E"},"outputs":[],"source":["encoded_labels_test = []\n","\n","for label_test in labels_test:\n","    if label_test == -1:\n","        encoded_labels_test.append([1,0,0])\n","    elif label_test == 0:\n","        encoded_labels_test.append([0,1,0])\n","    else:\n","        encoded_labels_test.append([0,0,1])\n","\n","encoded_labels_test = np.array(encoded_labels_test)  "]},{"cell_type":"code","execution_count":45,"metadata":{"id":"E08tBw9img-E"},"outputs":[],"source":["reviews_processed_test = []\n","unlabeled_processed_test = [] \n","for review_test in reviews_test:\n","    review_cool_one = ''.join([char for char in review_test if char not in digits])\n","    reviews_processed_test.append(review_cool_one)"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"OwgI9Xywmg-E"},"outputs":[],"source":["# Use PyVi for Vietnamese word tokenizer\n","word_reviews_test = []\n","all_words = []\n","for review_test in reviews_processed_test:\n","    review_test = ViTokenizer.tokenize(review_test.lower())\n","    word_reviews_test.append(review_test.split())"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"p02GxCh6mg-F"},"outputs":[],"source":["sequences_test = tokenizer.texts_to_sequences(word_reviews_test)\n","data_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n","labels_test = encoded_labels_test"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":534,"status":"ok","timestamp":1653989480441,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"jAqUMGInmg-F","outputId":"40acf056-b9c9-42ed-c767-423cc2054383"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X train and X validation tensor: (1050, 300)\n","Shape of label train and validation tensor: (1050, 3)\n"]}],"source":["print('Shape of X train and X validation tensor:',data_test.shape)\n","print('Shape of label train and validation tensor:', labels_test.shape)"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":596,"status":"ok","timestamp":1653989548454,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"LKclttiOmg-F","outputId":"6abe8e2e-7ed4-439f-8899-e6b30a044758"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7606 - loss: 2.0981\n"]}],"source":["score = model.evaluate(data_test, labels_test)"]},{"cell_type":"markdown","metadata":{},"source":["Let's check the metrics. Currently we support 2 metrics: loss aand compile_metrics\n","- loss: This is the objective that the model will try to minimize. In this case, we are using binary crossentropy loss, which is suitable for binary classification problems.\n","- compile_metrics: This is a list of metrics that will be computed for the model. In this case, we are using accuracy as the metric."]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":355,"status":"ok","timestamp":1653989552805,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"r31_uxxgmg-G","outputId":"2fb9d570-546b-4652-ca5f-5e6794fc6198"},"outputs":[{"name":"stdout","output_type":"stream","text":["loss: 248.18%\n","compile_metrics: 59.52%\n"]}],"source":["print(\"%s: %.2f%%\" % (model.metrics_names[0], score[0]*100))\n","print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v8O3z4IFmg-G"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"word2vec+cnn_v3.ipynb","provenance":[{"file_id":"1rFZZf9ECknkLNDv8so_kQNPhqain0RqJ","timestamp":1653989613942}]},"kernelspec":{"display_name":"christ","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
